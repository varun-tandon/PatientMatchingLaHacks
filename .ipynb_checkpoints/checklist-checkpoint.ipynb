{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "import fuzzy\n",
    "import re #regular expressions\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "soundex = fuzzy.Soundex(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_csv('Patient Matching Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_full_state_name(x):\n",
    "    states = {\n",
    "        \"AK\" : \"Alaska\",\n",
    "        \"AL\" : \"Alabama\",\n",
    "        \"AR\" : \"Arkansas\",\n",
    "        \"AS\" : \"American Samoa\",\n",
    "        \"AZ\" : \"Arizona\",\n",
    "        \"CA\" : \"California\",\n",
    "        \"CO\" : \"Colorado\",\n",
    "        \"CT\" : \"Connecticut\",\n",
    "        \"DC\" : \"District of Columbia\",\n",
    "        \"DE\" : \"Delaware\",\n",
    "        \"FL\" : \"Florida\",\n",
    "        \"GA\" : \"Georgia\",\n",
    "        \"GU\" : \"Guam\",\n",
    "        \"HI\" : \"Hawaii\",\n",
    "        \"IA\" : \"Iowa\",\n",
    "        \"ID\" : \"Idaho\",\n",
    "        \"IL\" : \"Illinois\",\n",
    "        \"IN\" : \"Indiana\",\n",
    "        \"KS\" : \"Kansas\",\n",
    "        \"KY\" : \"Kentucky\",\n",
    "        \"LA\" : \"Louisiana\",\n",
    "        \"MA\" : \"Massachusetts\",\n",
    "        \"MD\" : \"Maryland\",\n",
    "        \"ME\" : \"Maine\",\n",
    "        \"MI\" : \"Michigan\",\n",
    "        \"MN\" : \"Minnesota\",\n",
    "        \"MO\" : \"Missouri\",\n",
    "        \"MS\" : \"Mississippi\",\n",
    "        \"MT\" : \"Montana\",\n",
    "        \"NC\" : \"North Carolina\",\n",
    "        \"ND\" : \"North Dakota\",\n",
    "        \"NE\" : \"Nebraska\",\n",
    "        \"NH\" : \"New Hampshire\",\n",
    "        \"NJ\" : \"New Jersey\",\n",
    "        \"NM\" : \"New Mexico\",\n",
    "        \"NV\" : \"Nevada\",\n",
    "        \"NY\" : \"New York\",\n",
    "        \"OH\" : \"Ohio\",\n",
    "        \"OK\" : \"Oklahoma\",\n",
    "        \"OR\" : \"Oregon\",\n",
    "        \"PA\" : \"Pennsylvania\",\n",
    "        \"PR\" : \"Puerto Rico\",\n",
    "        \"RI\" : \"Rhode Island\",\n",
    "        \"SC\" : \"South Carolina\",\n",
    "        \"SD\" : \"South Dakota\",\n",
    "        \"TN\" : \"Tennessee\",\n",
    "        \"TX\" : \"Texas\",\n",
    "        \"UT\" : \"Utah\",\n",
    "        \"VA\" : \"Virginia\",\n",
    "        \"VI\" : \"Virgin Islands\",\n",
    "        \"VT\" : \"Vermont\",\n",
    "        \"WA\" : \"Washington\",\n",
    "        \"WI\" : \"Wisconsin\",\n",
    "        \"WV\" : \"West Virginia\",\n",
    "        \"WY\" : \"Wyoming\"\n",
    "    }\n",
    "    if len(x) < 3:\n",
    "        return x.upper()\n",
    "    else:\n",
    "        min_lev_dist_state = 'XX'\n",
    "        min_dist = 1000\n",
    "        for abb, state in states.items():\n",
    "            dist = levenshtein_distance(x, state)\n",
    "            if dist < min_dist:\n",
    "                min_lev_dist_state = abb\n",
    "                min_dist = dist\n",
    "        return min_lev_dist_state\n",
    "\n",
    "def swap_abb_state_name(x):\n",
    "    states = {\n",
    "        \"AK\" : \"Alaska\",\n",
    "        \"AL\" : \"Alabama\",\n",
    "        \"AR\" : \"Arkansas\",\n",
    "        \"AS\" : \"American Samoa\",\n",
    "        \"AZ\" : \"Arizona\",\n",
    "        \"CA\" : \"California\",\n",
    "        \"CO\" : \"Colorado\",\n",
    "        \"CT\" : \"Connecticut\",\n",
    "        \"DC\" : \"District of Columbia\",\n",
    "        \"DE\" : \"Delaware\",\n",
    "        \"FL\" : \"Florida\",\n",
    "        \"GA\" : \"Georgia\",\n",
    "        \"GU\" : \"Guam\",\n",
    "        \"HI\" : \"Hawaii\",\n",
    "        \"IA\" : \"Iowa\",\n",
    "        \"ID\" : \"Idaho\",\n",
    "        \"IL\" : \"Illinois\",\n",
    "        \"IN\" : \"Indiana\",\n",
    "        \"KS\" : \"Kansas\",\n",
    "        \"KY\" : \"Kentucky\",\n",
    "        \"LA\" : \"Louisiana\",\n",
    "        \"MA\" : \"Massachusetts\",\n",
    "        \"MD\" : \"Maryland\",\n",
    "        \"ME\" : \"Maine\",\n",
    "        \"MI\" : \"Michigan\",\n",
    "        \"MN\" : \"Minnesota\",\n",
    "        \"MO\" : \"Missouri\",\n",
    "        \"MS\" : \"Mississippi\",\n",
    "        \"MT\" : \"Montana\",\n",
    "        \"NC\" : \"North Carolina\",\n",
    "        \"ND\" : \"North Dakota\",\n",
    "        \"NE\" : \"Nebraska\",\n",
    "        \"NH\" : \"New Hampshire\",\n",
    "        \"NJ\" : \"New Jersey\",\n",
    "        \"NM\" : \"New Mexico\",\n",
    "        \"NV\" : \"Nevada\",\n",
    "        \"NY\" : \"New York\",\n",
    "        \"OH\" : \"Ohio\",\n",
    "        \"OK\" : \"Oklahoma\",\n",
    "        \"OR\" : \"Oregon\",\n",
    "        \"PA\" : \"Pennsylvania\",\n",
    "        \"PR\" : \"Puerto Rico\",\n",
    "        \"RI\" : \"Rhode Island\",\n",
    "        \"SC\" : \"South Carolina\",\n",
    "        \"SD\" : \"South Dakota\",\n",
    "        \"TN\" : \"Tennessee\",\n",
    "        \"TX\" : \"Texas\",\n",
    "        \"UT\" : \"Utah\",\n",
    "        \"VA\" : \"Virginia\",\n",
    "        \"VI\" : \"Virgin Islands\",\n",
    "        \"VT\" : \"Vermont\",\n",
    "        \"WA\" : \"Washington\",\n",
    "        \"WI\" : \"Wisconsin\",\n",
    "        \"WV\" : \"West Virginia\",\n",
    "        \"WY\" : \"Wyoming\",\n",
    "        'XX' : ''\n",
    "    }\n",
    "    min_lev_dist_state = 'XX'\n",
    "    min_dist = 1000\n",
    "    for abb in states.keys():\n",
    "        dist = levenshtein_distance(x, abb)\n",
    "        if dist < min_dist:\n",
    "            min_lev_dist_state = abb\n",
    "            min_dist = dist\n",
    "    return min_lev_dist_state\n",
    "    \n",
    "def clean_state_data(df):\n",
    "    df['Current State'].fillna('XX', inplace=True)\n",
    "    df['Current State'] = df['Current State'].apply(swap_full_state_name)\n",
    "    df['Current State'] = df['Current State'].apply(swap_abb_state_name)\n",
    "\n",
    "def clean_zip_code(df):\n",
    "    df['Current Zip Code'].fillna(0, inplace=True)\n",
    "    df['Zip Code String'] = df['Current Zip Code'].apply(lambda x: str(int(x)))\n",
    "    df['Zip Code String'] = df['Zip Code String'].replace('0', '00000')\n",
    "    df['National Area'] = df['Zip Code String'].apply(lambda x: int(x[0]))\n",
    "    df['Sectional Center'] = df['Zip Code String'].apply(lambda x: int(x[1:3]))\n",
    "    df['Delivery Area'] = df['Zip Code String'].apply(lambda x: int(x[3:]))\n",
    "    \n",
    "clean_state_data(df_patient)\n",
    "clean_zip_code(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering discrete and mixed data (from stackoverflow: https://datascience.stackexchange.com/questions/8681/clustering-for-mixed-numeric-and-nominal-discrete-data)\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "def gower_distance(X):\n",
    "    \"\"\"\n",
    "    This function expects a pandas dataframe as input\n",
    "    The data frame is to contain the features along the columns. Based on these features a\n",
    "    distance matrix will be returned which will contain the pairwise gower distance between the rows\n",
    "    All variables of object type will be treated as nominal variables and the others will be treated as \n",
    "    numeric variables.\n",
    "    Distance metrics used for:\n",
    "    Nominal variables: Dice distance (https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)\n",
    "    Numeric variables: Manhattan distance normalized by the range of the variable (https://en.wikipedia.org/wiki/Taxicab_geometry)\n",
    "    \"\"\"\n",
    "    individual_variable_distances = []\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        feature = X.iloc[:,[i]]\n",
    "        if feature.dtypes[0] == np.object:\n",
    "            feature_dist = DistanceMetric.get_metric('dice').pairwise(pd.get_dummies(feature))\n",
    "        else:\n",
    "            feature_dist = DistanceMetric.get_metric('manhattan').pairwise(feature) / np.ptp(feature.values)\n",
    "\n",
    "        individual_variable_distances.append(feature_dist)\n",
    "\n",
    "    return np.array(individual_variable_distances).mean(0)\n",
    "\n",
    "df_patient.fillna(0, inplace=True)\n",
    "X = gower_distance(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import OPTICS\n",
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.8).fit(X)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_date_string(x):\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(x['Date of Birth'], '%m/%d/%Y')\n",
    "        x['dob_string'] = str(parsed_date.strftime('%Y%m%d'))\n",
    "        return x\n",
    "    except:\n",
    "        bad_row = x['Date of Birth']\n",
    "        bad_row_splits = bad_row.split('/')\n",
    "        x['dob_string'] = bad_row_splits[2] + bad_row_splits[1] + bad_row_splits[0]\n",
    "        return x\n",
    "\n",
    "def clean_date_data(df):\n",
    "    return df.apply(convert_date_string, axis=1)\n",
    "\n",
    "df_patient = clean_date_data(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_sex_data(df):\n",
    "    df['Sex'].fillna('U', inplace=True)\n",
    "    df['Sex'] = df['Sex'].apply(lambda x: x[0].upper() if x[0].upper() in {'M', 'F'} else 'U')\n",
    "\n",
    "def fill_empty_name_data(df):\n",
    "    df['First Name'].fillna('', inplace=True)\n",
    "    df['Last Name'].fillna('', inplace=True)\n",
    "\n",
    "clean_sex_data(df_patient)\n",
    "fill_empty_name_data(df_patient)\n",
    "df_patient['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_patient_first_and_last_names(df):\n",
    "    df['rnaFirstName'] = df['First Name'].str.replace('[^a-zA-Z]', '').str.lower()\n",
    "    df['rnaLastName'] = df['Last Name'].str.replace('[^a-zA-Z]', '').str.lower()\n",
    "\n",
    "normalize_patient_first_and_last_names(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_name_hash(first_name, last_name, gender, dob):\n",
    "    SALT = 'OATEST'\n",
    "    hasher = hashlib.sha1()\n",
    "    hasher.update('{}{}~{}{}'.format(SALT, dob, gender, first_name).encode('utf-8'))\n",
    "    return '{}~{}'.format(hasher.hexdigest(), last_name)\n",
    "\n",
    "def partial_hash(first_name, last_name, gender, dob):\n",
    "    # first three of first and last name\n",
    "    first_name = first_name[:3] if len(first_name) >= 3 else 'X' * (3 - len(first_name)) + first_name\n",
    "    last_name = last_name[:3] if len(last_name) >= 3 else 'X' * (3 - len(last_name)) + last_name \n",
    "    SALT = 'OATEST'\n",
    "    hasher = hashlib.sha1()\n",
    "    hasher.update('{}{}~{}{}'.format(SALT, dob, gender, first_name).encode('utf-8'))\n",
    "    return '{}~{}'.format(hasher.hexdigest(), last_name)\n",
    "\n",
    "def df_full_name_hash(x):\n",
    "    return full_name_hash(x['First Name'], x['Last Name'], x['Sex'], x['dob_string'])\n",
    "\n",
    "def df_partial_hash(x):\n",
    "    return partial_hash(x['First Name'], x['Last Name'], x['Sex'], x['dob_string'])\n",
    "\n",
    "def create_hash_tokens(df):\n",
    "    df['full_name_hash'] = df.apply(df_full_name_hash, axis=1)\n",
    "    df['partial_name_hash'] = df.apply(df_partial_hash, axis=1)\n",
    "    \n",
    "create_hash_tokens(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findConfidenceLevel(first_name1, last_name1, rna_first_name1, rna_last_name1, first_name2, last_name2, rna_first_name2, rna_last_name2):\n",
    "    if rna_first_name1 == rna_first_name2 and rna_last_name1 == rna_last_name2:\n",
    "        return 100\n",
    "    elif rna_last_name1 == rna_last_name2 and rna_first_name1[:4] == rna_first_name2[:4]:\n",
    "        return 90\n",
    "    elif rna_last_name1 == rna_last_name2:\n",
    "        return 85\n",
    "    elif rna_last_name1[0:5] == rna_last_name2[0:5] and rna_first_name1[:4] == rna_first_name2[:4]:\n",
    "        return 80\n",
    "    elif soundex(last_name1) == soundex(last_name2) and soundex(first_name1) == soundex(first_name2):\n",
    "        return 79\n",
    "    elif soundex(rna_last_name1) == soundex(rna_last_name2) and soundex(rna_first_name1) == soundex(rna_first_name2):\n",
    "        return 77\n",
    "    elif rna_first_name1 == rna_first_name2 and soundex(rna_last_name1[:4]) == soundex(rna_last_name2[:4]):\n",
    "        return 76\n",
    "    elif rna_first_name1 == rna_first_name2:\n",
    "        return 60\n",
    "    else:\n",
    "        return 50\n",
    "    \n",
    "def findConfidenceLevel2(first_name1, last_name1, rna_first_name1, rna_last_name1, first_name2, last_name2, rna_first_name2, rna_last_name2):   \n",
    "    if rna_first_name1 == rna_first_name2 and rna_last_name1 == rna_last_name2:\n",
    "        return 100\n",
    "    elif rna_last_name1 == rna_last_name2 and rna_first_name1[:4] == rna_first_name2[:4]:\n",
    "        return 90\n",
    "    elif rna_last_name1 == rna_last_name2 and soundex(first_name1) == soundex(first_name2):\n",
    "        return 85\n",
    "    elif rna_last_name1[0:5] == rna_last_name2[0:5] and rna_first_name1[:4] == rna_first_name2[:4]:\n",
    "        return 80\n",
    "    elif soundex(last_name1) == soundex(last_name2) and soundex(first_name1) == soundex(first_name2):\n",
    "        return 79\n",
    "    elif soundex(rna_last_name1) == soundex(rna_last_name2) and soundex(rna_first_name1) == soundex(rna_first_name2):\n",
    "        return 77\n",
    "    elif rna_first_name1 == rna_first_name2 and soundex(rna_last_name1[:4]) == soundex(rna_last_name2[:4]):\n",
    "        return 76\n",
    "    elif rna_last_name1 == rna_last_name2:\n",
    "        return 75\n",
    "    elif rna_first_name1 == rna_first_name2:\n",
    "        return 60\n",
    "    else:\n",
    "        return 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confidence_matrix(confidence_type, confidence_func, df, threshold):\n",
    "    matrix = np.zeros((df.shape[0], df.shape[0]))\n",
    "    for index1, row1 in df.iterrows():\n",
    "        for index2, row2 in df.iterrows():\n",
    "            conf = confidence_func(\n",
    "                    row1['First Name'],\n",
    "                    row1['Last Name'],\n",
    "                    row1['rnaFirstName'],\n",
    "                    row1['rnaLastName'],\n",
    "                    row2['First Name'],\n",
    "                    row2['Last Name'],\n",
    "                    row2['rnaFirstName'],\n",
    "                    row2['rnaLastName']\n",
    "            )\n",
    "            if conf > threshold:\n",
    "                matrix[index1][index2] = 1\n",
    "            else:\n",
    "                matrix[index1][index2] = 0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_matrix = generate_confidence_matrix(2, findConfidenceLevel2, df_patient, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "graph = csr_matrix(confidence_matrix)\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(labels, df):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index1, row1 in df.iterrows():\n",
    "        for index2, row2 in df.iterrows():\n",
    "            if index1 >= index2:\n",
    "                continue\n",
    "            if row1['GroupID'] == row2['GroupID']: # P\n",
    "                if labels[index1] == labels[index2]: # T\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            else: # N\n",
    "                if labels[index1] == labels[index2]: # F\n",
    "                    fp += 1\n",
    "                else: # T\n",
    "                    tn += 1\n",
    "    return (tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = measure_accuracy(clustering.labels_, df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroupID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Patient Acct #</th>\n",
       "      <th>First Name</th>\n",
       "      <th>MI</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Current Street 1</th>\n",
       "      <th>Current Street 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Previous City</th>\n",
       "      <th>Previous State</th>\n",
       "      <th>Previous Zip Code</th>\n",
       "      <th>Zip Code String</th>\n",
       "      <th>National Area</th>\n",
       "      <th>Sectional Center</th>\n",
       "      <th>Delivery Area</th>\n",
       "      <th>dob_string</th>\n",
       "      <th>rnaFirstName</th>\n",
       "      <th>rnaLastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>247028705-7</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>J</td>\n",
       "      <td>Power</td>\n",
       "      <td>9/20/1945</td>\n",
       "      <td>M</td>\n",
       "      <td>1858 Sullivan Parkway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mount Vernon</td>\n",
       "      <td>New York</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>93726</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>19450920</td>\n",
       "      <td>sutton</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suttin</td>\n",
       "      <td>James</td>\n",
       "      <td>Power</td>\n",
       "      <td>9/21/1945</td>\n",
       "      <td>M</td>\n",
       "      <td>1859 Sullivan Parkway</td>\n",
       "      <td>#2</td>\n",
       "      <td>...</td>\n",
       "      <td>Mount Vernon</td>\n",
       "      <td>New York</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>93726</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>19450921</td>\n",
       "      <td>suttin</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>247028705-7</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>J</td>\n",
       "      <td>Power</td>\n",
       "      <td>9/20/1945</td>\n",
       "      <td>M</td>\n",
       "      <td>1858 Sullivan Parkway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93726</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>19450920</td>\n",
       "      <td>sutton</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power</td>\n",
       "      <td>9/20/1954</td>\n",
       "      <td>M</td>\n",
       "      <td>1858 Sullivan Parkway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93726</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>19540920</td>\n",
       "      <td>sutton</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POWER</td>\n",
       "      <td>9/20/1954</td>\n",
       "      <td>M</td>\n",
       "      <td>1858 SULLIVAN PKWAY</td>\n",
       "      <td>APT 2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93726</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>19540920</td>\n",
       "      <td>sutton</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>61</td>\n",
       "      <td>197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>5/16/1972</td>\n",
       "      <td>M</td>\n",
       "      <td>16595 City View Lane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98684</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>19720516</td>\n",
       "      <td>bill</td>\n",
       "      <td>smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>62</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>5/16/1972</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19720516</td>\n",
       "      <td>bill</td>\n",
       "      <td>smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>63</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Field</td>\n",
       "      <td>3/17/2010</td>\n",
       "      <td>F</td>\n",
       "      <td>9850 Kelso Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98626</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>26</td>\n",
       "      <td>20100317</td>\n",
       "      <td>sarah</td>\n",
       "      <td>field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Field</td>\n",
       "      <td>3/17/2010</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20100317</td>\n",
       "      <td>sara</td>\n",
       "      <td>field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>65</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Field</td>\n",
       "      <td>3/17/2010</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20100317</td>\n",
       "      <td>sara</td>\n",
       "      <td>field</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GroupID  PatientID Patient Acct # First Name     MI Last Name  \\\n",
       "0          1          1    247028705-7     Sutton      J     Power   \n",
       "1          1          2            NaN     Suttin  James     Power   \n",
       "2          1          3    247028705-7     Sutton      J     Power   \n",
       "3          1          4            NaN     Sutton    NaN     Power   \n",
       "4          1          5            NaN     SUTTON    NaN     POWER   \n",
       "..       ...        ...            ...        ...    ...       ...   \n",
       "196       61        197            NaN       Bill    NaN     Smith   \n",
       "197       62        198            NaN       Bill    NaN     Smith   \n",
       "198       63        199            NaN      Sarah    NaN     Field   \n",
       "199       64        200            NaN       Sara    NaN     Field   \n",
       "200       65        201            NaN       Sara    NaN     Field   \n",
       "\n",
       "    Date of Birth Sex       Current Street 1 Current Street 2  ...  \\\n",
       "0       9/20/1945   M  1858 Sullivan Parkway              NaN  ...   \n",
       "1       9/21/1945   M  1859 Sullivan Parkway               #2  ...   \n",
       "2       9/20/1945   M  1858 Sullivan Parkway              NaN  ...   \n",
       "3       9/20/1954   M  1858 Sullivan Parkway              NaN  ...   \n",
       "4       9/20/1954   M    1858 SULLIVAN PKWAY            APT 2  ...   \n",
       "..            ...  ..                    ...              ...  ...   \n",
       "196     5/16/1972   M   16595 City View Lane              NaN  ...   \n",
       "197     5/16/1972   M                    NaN              NaN  ...   \n",
       "198     3/17/2010   F        9850 Kelso Road              NaN  ...   \n",
       "199     3/17/2010   F                    NaN              NaN  ...   \n",
       "200     3/17/2010   F                    NaN              NaN  ...   \n",
       "\n",
       "    Previous City Previous State  Previous Zip Code Zip Code String  \\\n",
       "0    Mount Vernon       New York            10557.0           93726   \n",
       "1    Mount Vernon       New York            10557.0           93726   \n",
       "2             NaN            NaN                NaN           93726   \n",
       "3             NaN            NaN                NaN           93726   \n",
       "4             NaN            NaN                NaN           93726   \n",
       "..            ...            ...                ...             ...   \n",
       "196           NaN            NaN                NaN           98684   \n",
       "197           NaN            NaN                NaN           00000   \n",
       "198           NaN            NaN                NaN           98626   \n",
       "199           NaN            NaN                NaN           00000   \n",
       "200           NaN            NaN                NaN           00000   \n",
       "\n",
       "    National Area Sectional Center Delivery Area dob_string rnaFirstName  \\\n",
       "0               9               37            26   19450920       sutton   \n",
       "1               9               37            26   19450921       suttin   \n",
       "2               9               37            26   19450920       sutton   \n",
       "3               9               37            26   19540920       sutton   \n",
       "4               9               37            26   19540920       sutton   \n",
       "..            ...              ...           ...        ...          ...   \n",
       "196             9               86            84   19720516         bill   \n",
       "197             0                0             0   19720516         bill   \n",
       "198             9               86            26   20100317        sarah   \n",
       "199             0                0             0   20100317         sara   \n",
       "200             0                0             0   20100317         sara   \n",
       "\n",
       "    rnaLastName  \n",
       "0         power  \n",
       "1         power  \n",
       "2         power  \n",
       "3         power  \n",
       "4         power  \n",
       "..          ...  \n",
       "196       smith  \n",
       "197       smith  \n",
       "198       field  \n",
       "199       field  \n",
       "200       field  \n",
       "\n",
       "[201 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_data('Patient Matching Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
